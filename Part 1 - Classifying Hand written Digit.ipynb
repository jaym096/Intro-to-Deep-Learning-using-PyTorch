{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning using PyTorch\n",
    "In this notebook I'm trying to work on real life application to learn PyTorch as well as Deep Learning. I'll be building a multi-layer neural network to identify text in an image. For this project I'm using MNIST dataset which consists of greyscale handwritten digits. Each image is a 28x28 pixels. the goal is to build a neural network that can take one of these images and predict the digit in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import important libraries\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, we need to get our dataset. This is provided through the torchvision package. The code below will download the MNIST dataset, then create training and test datasets for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])\n",
    "\n",
    "#Download and load the training data\n",
    "trainset = datasets.MNIST('~/data/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we flatten the batch of images images and then build a multi-layer network with 784 input units, 256 hidden units, and 10 output units using random tensors for the weights and biases. We are using ReLU activation for the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 10 outputs for our network. We want to pass in an image to our network and get out a probability distribution over the classes that tells us the likely class(es) the image belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and Activation\n",
    "Given this is a classification problem, we'll be using the softmax function to predict the class probabilities. With a softmax output, we use a cross-entropy as the loss (**_nn.CrossEntropyLoss_**). To actually calculate the loss, you first define the criterion then pass in the output of your network and the correct labels. However, one important point to note is that you can write cross-entropy loss separately using **_nn.LogSoftmax_** and **_nn.NLLLoss_** (Negative Log Likelihood Loss). _nn.CrossEntropyLoss_ combines these 2 in one single class.\n",
    "\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, **nn.Sequential**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd\n",
    "Now since we've calculated the loss, how do we use it to perform backpropagation? Torch provides a module, **_autograd_**, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way.\n",
    "\n",
    "The gradients are computed with respect to some variable z with z.backward(). This does a backward pass through the operations that created z.\n",
    "\n",
    "The autograd module keeps track of these operations and knows how to calculate the gradient for each one. In this way, it's able to calculate the gradients for a chain of operations, with respect to any one tensor.\n",
    "\n",
    "Thus to calculate gradients with respect to loss we calculate the loss and call loss.backward(), the gradients for the parameters are calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network\n",
    "There's one last piece we need to start training, an optimizer that we'll use to update the weights with the gradients. We get these from PyTorch's optim package. For example we can use stochastic gradient descent with optim.SGD. You can see how to define an optimizer below.\n",
    "\n",
    "**imp:** When you do multiple backwards passes with the same parameters, the gradients are accumulated. This means that you need to zero the gradients on each training pass or you'll retain gradients from previous training batches. Use _optimizer.zero_grad()_ (we've performed this operation above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0365215287343272\n",
      "Training loss: 0.38236434913393275\n",
      "Training loss: 0.32250645601037725\n",
      "Training loss: 0.29059839316967456\n"
     ]
    }
   ],
   "source": [
    "# Build a feed forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1)) #dimension along which to calculate LogSoftmax.\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the network trained, we can check out it's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "\n",
    "ps = ps.data.numpy().squeeze()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "ax1.axis('off')\n",
    "ax2.barh(np.arange(10), ps)\n",
    "ax2.set_aspect(0.1)\n",
    "ax2.set_yticks(np.arange(10))\n",
    "ax2.set_yticklabels(np.arange(10))\n",
    "ax2.set_title('Class Probability')\n",
    "ax2.set_xlim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
